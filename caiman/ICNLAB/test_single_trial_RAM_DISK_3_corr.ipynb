{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad2f8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages and Initializing...\n",
      "C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2.tsm 640\n",
      "Cleaning up R:/ drive...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#version 3 of test_single_trial_RAM_DISK.py with updated VOLPY from old single trial .py file\n",
    "# TO RUN: conda activate caiman\n",
    "# # python C:\\Users\\ICNLab\\caiman_data\\test_single_trial_RAM_DISK_3.py C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2.tsm\n",
    "\n",
    "fname = r'C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2.tsm'\n",
    "#fname = r'C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV3_T3new\\FOV3_T3.tsm'\n",
    "\n",
    "print(\"Importing packages and Initializing...\")\n",
    "from base64 import b64encode\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import imageio\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, display, clear_output\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.use(\"Agg\")  # non-interactive backend\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "#import to cover extras from single_trial.py\n",
    "import gc\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import savgol_filter\n",
    "import sys\n",
    "import mat73\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "        get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.utils.utils import download_demo, download_model\n",
    "from caiman.source_extraction.volpy import utils\n",
    "from caiman.source_extraction.volpy.volparams import volparams\n",
    "from caiman.source_extraction.volpy.volpy import VOLPY\n",
    "from caiman.source_extraction.volpy.mrcnn import visualize, neurons\n",
    "import caiman.source_extraction.volpy.mrcnn.model as modellib\n",
    "from caiman.summary_images import local_correlations_movie_offline\n",
    "from caiman.summary_images import mean_image\n",
    "from caiman.paths import caiman_datadir\n",
    "from caiman.summary_images import local_correlations_movie_in_memory\n",
    "import gc\n",
    "\n",
    "\n",
    "logging.basicConfig(format=\n",
    "                    \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s]\" \\\n",
    "                    \"[%(process)d] %(message)s\",\n",
    "                    level=logging.ERROR)\n",
    "\n",
    "##\n",
    "#fname = r'C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2.tsm'\n",
    "fr = 640\n",
    "print(fname, fr)\n",
    "\n",
    "\n",
    "##\n",
    "# Cleanup R:/ drive\n",
    "print(\"Cleaning up R:/ drive...\")\n",
    "def safe_close_mmap(arr):\n",
    "    try:\n",
    "        if hasattr(arr, \"base\") and hasattr(arr.base, \"close\"):\n",
    "            arr.base.close()\n",
    "    except Exception as e:\n",
    "        print(\"close failed:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Delete any Python references to memmaps pointing to R:/\n",
    "try:\n",
    "    safe_close_mmap(Yr)  # or whatever your memmap object is called\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    safe_close_mmap(mmap_file_rig)  # or whatever your memmap object is called\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "gc.collect()  # force Python to release the memory mapping\n",
    "\n",
    "# 2. Delete all files in R:/\n",
    "for f in Path(r'R:/').glob('*'):\n",
    "    if f.is_file():\n",
    "        f.unlink()\n",
    "print(\"Cleared all files from R:/\")\n",
    "\n",
    "\n",
    "##\n",
    "pw_rigid = False  # flag for pw-rigid motion correction\n",
    "gsig_filt = (3, 3)  # size of filter, in general gSig (see below),\n",
    "# change this one if algorithm does not work\n",
    "max_shifts = (5, 5)  # maximum allowed rigid shift\n",
    "strides = (48, 48)  # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)  # overlap between paths (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'\n",
    "use_cuda = True\n",
    "\n",
    "opts_dict = {\n",
    "    'fnames': fname,\n",
    "    'fr': fr,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gsig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan,\n",
    "    'use_cuda': use_cuda\n",
    "}\n",
    "\n",
    "opts = volparams(params_dict=opts_dict)\n",
    "\n",
    "##\n",
    "print(\"Loading data...\")\n",
    "m_orig = cm.load(fname)\n",
    "ds_ratio = 0.2\n",
    "\n",
    "##\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "            backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "##\n",
    "print(\"Motion correction...\")\n",
    "mc = MotionCorrect(fname, dview=dview, **opts.get_group('motion'))\n",
    "mc.motion_correct(save_movie=True)\n",
    "#about 2.3 minutes for 12800 frames (2m 13-21 s)\n",
    "print(\"Done.\")\n",
    "\n",
    "##\n",
    "print(\"Loading corrected movie...\")\n",
    "m_rig = cm.load(mc.mmap_file) # 11s\n",
    "ds_ratio = 0.2\n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "##\n",
    "print(\"Saving stabilized movie to RAM-disk...\")\n",
    "# Path to RAM disk memmap\n",
    "p = Path(fname)\n",
    "ram_path = Path(r'R:/') / f\"{p.stem}_rig__d1_{m_rig.shape[1]}_d2_{m_rig.shape[2]}_d3_1_order_C_frames_{m_rig.shape[0]}.mmap\"\n",
    "ram_path = str(ram_path).replace(\"/\", \"\\\\\")\n",
    "\n",
    "# Create memmap in RAM-disk with same shape as m_rig\n",
    "mmap_file_rig = np.memmap(ram_path, dtype='float32', mode='w+', shape=m_rig.shape, order='F') #Was C before\n",
    "\n",
    "# Copy stabilized movie data into memmap\n",
    "mmap_file_rig[:] = m_rig[:]\n",
    "\n",
    "# Flush to make sure data is written\n",
    "mmap_file_rig.flush()\n",
    "\n",
    "mmap_list = [mmap_file_rig]\n",
    "\n",
    "print(\"Saved stabilized memmap to RAM-disk:\", ram_path)\n",
    "\n",
    "##\n",
    "\n",
    "print(\"Computing mean and correlation images...\")\n",
    "img = np.mean(m_rig, axis=0)\n",
    "img = (img-np.mean(img))/np.std(img)\n",
    "\n",
    "gaussian_blur = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f68bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:/FOV1_T2_rig__d1_512_d2_512_d3_1_order_F_frames_12800.mmap\n"
     ]
    }
   ],
   "source": [
    "print(mc.mmap_file[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa68abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# 1. Parameters\n",
    "# ===============================\n",
    "VIDEO_PATH = \"video.mmap\"   # path to your mmap file\n",
    "SHAPE = (12800, 512, 512)\n",
    "DTYPE = np.float32\n",
    "\n",
    "FRAME_RATE = 640.0  # Hz (EDIT THIS IF NEEDED)\n",
    "BANDPASS = (5, 300) # Hz #70,300\n",
    "\n",
    "WINDOW = 3\n",
    "HALF = WINDOW // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36df72e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded video: (12800, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# 2. Load memory-mapped video\n",
    "# ===============================\n",
    "video = np.memmap(\n",
    "    mc.mmap_file[0],\n",
    "    dtype=DTYPE,\n",
    "    mode=\"r\",\n",
    "    shape=(SHAPE[0], SHAPE[2], SHAPE[1]),\n",
    "    order=\"C\"\n",
    ").swapaxes(1, 2)\n",
    "\n",
    "T, H, W = video.shape\n",
    "print(f\"Loaded video: {video.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f35f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ===============================\n",
    "# # 3. Band-pass filter design\n",
    "# # ===============================\n",
    "# def bandpass_filter(data, fs, low, high, order=3):\n",
    "#     nyq = 0.5 * fs\n",
    "#     b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "#     return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "# ===============================\n",
    "# 3. High-pass filter (bandpass-compatible API)\n",
    "# ===============================\n",
    "def bandpass_filter(data, fs, low, high=None, order=3):\n",
    "    \"\"\"\n",
    "    High-pass filter using the 'low' cutoff.\n",
    "    The 'high' argument is accepted for API compatibility but ignored.\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, low / nyq, btype=\"high\")\n",
    "    return filtfilt(b, a, data, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98cf753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pixel: (y=320, x=210)\n",
      "Selected pixel: (y=179, x=212)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# 4. Example: filter one pixel (DEBUG)\n",
    "# ===============================\n",
    "# y, x = 256, 256\n",
    "# raw_trace = video[:, y, x]\n",
    "# filt_trace = bandpass_filter(raw_trace, FRAME_RATE, *BANDPASS)\n",
    "\n",
    "# plt.figure(figsize=(8, 3))\n",
    "# plt.plot(raw_trace[:2000], label=\"Raw\", alpha=0.5)\n",
    "# plt.plot(filt_trace[:2000], label=\"Band-passed\", lw=2)\n",
    "# plt.title(\"Single pixel trace (first 2 seconds)\")\n",
    "# plt.xlabel(\"Frame\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 4. Interactive pixel selection (DEBUG)\n",
    "# ===============================\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "first_frame = video[0]\n",
    "im = ax.imshow(first_frame, cmap=\"gray\")\n",
    "ax.set_title(\"Click on a pixel to inspect its time trace\")\n",
    "ax.axis(\"off\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "coords = []\n",
    "\n",
    "def onclick(event):\n",
    "    if event.inaxes != ax:\n",
    "        return\n",
    "\n",
    "    x = int(event.xdata)\n",
    "    y = int(event.ydata)\n",
    "    coords.append((y, x))\n",
    "\n",
    "    ax.plot(x, y, 'ro')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    print(f\"Selected pixel: (y={y}, x={x})\")\n",
    "\n",
    "    # Extract and filter trace\n",
    "    raw_trace = video[:, y, x]\n",
    "    filt_trace = bandpass_filter(\n",
    "        raw_trace, FRAME_RATE, *BANDPASS\n",
    "    )\n",
    "\n",
    "    # Plot traces\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(raw_trace[:2000], label=\"Raw\", alpha=0.5)\n",
    "    plt.plot(filt_trace[:2000], label=\"Band-passed\", lw=2)\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"Fluorescence\")\n",
    "    plt.title(f\"Pixel (y={y}, x={x}) – first 2 seconds\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3caa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI center: (y=149, x=273)\n",
      "ROI radius: 6 px\n",
      "ROI radius: 7 px\n",
      "ROI radius: 8 px\n",
      "ROI radius: 9 px\n",
      "ROI radius: 10 px\n",
      "ROI radius: 11 px\n",
      "ROI radius: 12 px\n",
      "ROI radius: 13 px\n",
      "ROI radius: 14 px\n",
      "Extracting 613 pixels from ROI\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 4. Interactive circular ROI selection (POC)\n",
    "# ===============================\n",
    "\n",
    "# DISPLAY_SECONDS = 20  # seconds of data to plot\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# first_frame = video[0]\n",
    "# im = ax.imshow(first_frame, cmap=\"gray\")\n",
    "# ax.set_title(\"Click: set center | Scroll: change radius | Enter: extract\")\n",
    "# ax.axis(\"off\")\n",
    "# plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "# roi_center = None\n",
    "# roi_radius = 5  # initial radius (pixels)\n",
    "# circle_artist = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Parameters\n",
    "# ===============================\n",
    "DISPLAY_SECONDS = 20\n",
    "TILE_SIZE = 8\n",
    "roi_radius = 5  # initial radius (pixels)\n",
    "roi_center = None\n",
    "circle_artist = None\n",
    "\n",
    "# ===============================\n",
    "# First frame & coherence image\n",
    "# ===============================\n",
    "first_frame = video[0]  # shape (H, W)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(first_frame, cmap=\"gray\")\n",
    "ax.set_title(\"Click: set center | Scroll: change radius | Enter: extract\")\n",
    "ax.axis(\"off\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "# Overlay coherence image\n",
    "vmax = np.percentile(spike_norm, 99)\n",
    "overlay = ax.imshow(spike_norm, cmap=\"viridis\", alpha=0.5, vmin=0, vmax=vmax)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_circle():\n",
    "    global circle_artist\n",
    "    if circle_artist is not None:\n",
    "        circle_artist.remove()\n",
    "\n",
    "    circle_artist = plt.Circle(\n",
    "        (roi_center[1], roi_center[0]),\n",
    "        roi_radius,\n",
    "        edgecolor=\"red\",\n",
    "        facecolor=\"none\",\n",
    "        lw=2\n",
    "    )\n",
    "    ax.add_patch(circle_artist)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "def onclick(event):\n",
    "    global roi_center\n",
    "    if event.inaxes != ax:\n",
    "        return\n",
    "\n",
    "    roi_center = (int(event.ydata), int(event.xdata))\n",
    "    draw_circle()\n",
    "    print(f\"ROI center: (y={roi_center[0]}, x={roi_center[1]})\")\n",
    "\n",
    "\n",
    "def onscroll(event):\n",
    "    global roi_radius\n",
    "    if roi_center is None:\n",
    "        return\n",
    "\n",
    "    if event.button == 'up':\n",
    "        roi_radius += 1\n",
    "    elif event.button == 'down' and roi_radius > 1:\n",
    "        roi_radius -= 1\n",
    "\n",
    "    draw_circle()\n",
    "    print(f\"ROI radius: {roi_radius} px\")\n",
    "\n",
    "\n",
    "def onkeypress(event):\n",
    "    if event.key != 'enter' or roi_center is None:\n",
    "        return\n",
    "\n",
    "    y0, x0 = roi_center\n",
    "\n",
    "    yy, xx = np.ogrid[:H, :W]\n",
    "    mask = (yy - y0) ** 2 + (xx - x0) ** 2 <= roi_radius ** 2\n",
    "    n_pixels = mask.sum()\n",
    "\n",
    "    print(f\"Extracting {n_pixels} pixels from ROI\")\n",
    "\n",
    "    # Extract summed signal\n",
    "    roi_trace = video[:, mask].sum(axis=1)\n",
    "\n",
    "    # Band-pass filter\n",
    "    filt_trace = bandpass_filter(\n",
    "        roi_trace, FRAME_RATE, *BANDPASS\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    n_show = min(int(DISPLAY_SECONDS * FRAME_RATE), len(roi_trace))\n",
    "    t = np.arange(n_show) / FRAME_RATE\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(t, roi_trace[:n_show], label=\"Summed ROI (raw)\", alpha=0.5)\n",
    "    plt.plot(t, filt_trace[:n_show], label=\"Band-passed\", lw=2)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Summed fluorescence\")\n",
    "    plt.title(\n",
    "        f\"Circular ROI (r={roi_radius}px, n={n_pixels})\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Connect callbacks\n",
    "fig.canvas.mpl_connect(\"button_press_event\", onclick)\n",
    "fig.canvas.mpl_connect(\"scroll_event\", onscroll)\n",
    "fig.canvas.mpl_connect(\"key_press_event\", onkeypress)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "940c8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing tiles: 100%|██████████| 16384/16384 [00:38<00:00, 429.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================\n",
    "# Parameters\n",
    "# ===============================\n",
    "TILE_SIZE = 4\n",
    "H, W = 512, 512\n",
    "FRAME_RATE = FRAME_RATE   # already defined\n",
    "BANDPASS = BANDPASS       # (low, high), high ignored\n",
    "DISPLAY_CLIP = 99         # percentile for visualization\n",
    "\n",
    "# ===============================\n",
    "# Robust spike metric\n",
    "# ===============================\n",
    "def spikiness_metric(trace, z_thresh=3.0):\n",
    "    \"\"\"\n",
    "    Estimate amount of outlying activity in a trace.\n",
    "    Uses robust z-score (MAD-based) and measures tail mass.\n",
    "    \"\"\"\n",
    "    trace = trace - np.median(trace)\n",
    "    mad = np.median(np.abs(trace)) + 1e-9\n",
    "    z = trace / mad\n",
    "\n",
    "    # Fraction of samples beyond threshold\n",
    "    spike_fraction = np.mean(np.abs(z) > z_thresh)\n",
    "\n",
    "    # Mean excess magnitude beyond threshold\n",
    "    spike_energy = np.mean(np.abs(z[np.abs(z) > z_thresh])) if np.any(np.abs(z) > z_thresh) else 0.0\n",
    "\n",
    "    return spike_fraction + 0.1 * spike_energy\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Output map (tile-resolution)\n",
    "# ===============================\n",
    "n_tiles_y = H // TILE_SIZE\n",
    "n_tiles_x = W // TILE_SIZE\n",
    "\n",
    "tile_spike_map = np.zeros((n_tiles_y, n_tiles_x), dtype=np.float32)\n",
    "\n",
    "# ===============================\n",
    "# Main loop\n",
    "# ===============================\n",
    "with tqdm(total=n_tiles_y * n_tiles_x, desc=\"Analyzing tiles\") as pbar:\n",
    "    for ty in range(n_tiles_y):\n",
    "        for tx in range(n_tiles_x):\n",
    "\n",
    "            y0 = ty * TILE_SIZE\n",
    "            y1 = y0 + TILE_SIZE\n",
    "            x0 = tx * TILE_SIZE\n",
    "            x1 = x0 + TILE_SIZE\n",
    "\n",
    "            # Extract tile: shape (T, 16, 16)\n",
    "            tile = video[:, y0:y1, x0:x1]\n",
    "\n",
    "            # Sum all pixels\n",
    "            tile_trace = tile.reshape(T, -1).sum(axis=1)\n",
    "\n",
    "            # High-pass filter (bandpass-compatible)\n",
    "            tile_trace_filt = bandpass_filter(\n",
    "                tile_trace, FRAME_RATE, *BANDPASS\n",
    "            )\n",
    "\n",
    "            # Compute spikiness\n",
    "            tile_spike_map[ty, tx] = spikiness_metric(tile_trace_filt)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "# ===============================\n",
    "# Expand tile map back to image resolution\n",
    "# ===============================\n",
    "spike_image = np.repeat(\n",
    "    np.repeat(tile_spike_map, TILE_SIZE, axis=0),\n",
    "    TILE_SIZE, axis=1\n",
    ")\n",
    "\n",
    "# # ===============================\n",
    "# # Visualization\n",
    "# # ===============================\n",
    "# vmax = np.percentile(spike_image, DISPLAY_CLIP)\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.imshow(spike_image, cmap=\"hot\", vmin=0, vmax=vmax)\n",
    "# plt.title(\"Grid-based spike activity (\"+str(TILE_SIZE)+\"×\"+str(TILE_SIZE)+\" tiles)\")\n",
    "# plt.colorbar(label=\"Spikiness score\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# ===============================\n",
    "# Visualization (normalized)\n",
    "# ===============================\n",
    "\n",
    "# Normalize spike image to [0, 1]\n",
    "spike_norm = spike_image.astype(np.float32)\n",
    "spike_norm -= spike_norm.min()\n",
    "spike_norm /= (spike_norm.max() + 1e-9)  # avoid division by zero\n",
    "\n",
    "# Optionally clip at DISPLAY_CLIP percentile for contrast\n",
    "vmax = np.percentile(spike_norm, DISPLAY_CLIP / 100 * 1.0)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(spike_norm, cmap=\"hot\", vmin=0, vmax=vmax)\n",
    "plt.title(f\"Grid-based spike activity ({TILE_SIZE}×{TILE_SIZE} tiles)\")\n",
    "plt.colorbar(label=\"Spikiness score\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec068474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Visualization\n",
    "# ===============================\n",
    "vmax = np.percentile(spike_image, DISPLAY_CLIP)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(spike_image, cmap=\"hot\", vmin=0, vmax=vmax)\n",
    "plt.title(\"Grid-based spike activity (\"+str(TILE_SIZE)+\"×\"+str(TILE_SIZE)+\" tiles)\")\n",
    "plt.colorbar(label=\"Spikiness score\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df7e5c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing coherence: 100%|██████████| 16384/16384 [01:53<00:00, 144.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================\n",
    "# Parameters\n",
    "# ===============================\n",
    "TILE_SIZE = 4\n",
    "H, W = 512, 512\n",
    "FRAME_RATE = FRAME_RATE\n",
    "BANDPASS = BANDPASS      # (low, high), high ignored\n",
    "DISPLAY_CLIP = 99\n",
    "\n",
    "# ===============================\n",
    "# Coherence metric\n",
    "# ===============================\n",
    "def coherence_metric(tile_filt):\n",
    "    \"\"\"\n",
    "    tile_filt: shape (T, Npix)\n",
    "    Returns mean pixel-to-tile correlation.\n",
    "    \"\"\"\n",
    "    # Tile reference (subthreshold signals sum coherently)\n",
    "    ref = tile_filt.mean(axis=1)\n",
    "\n",
    "    ref -= ref.mean()\n",
    "    ref_std = ref.std() + 1e-9\n",
    "\n",
    "    # Normalize reference\n",
    "    ref /= ref_std\n",
    "\n",
    "    # Normalize pixels\n",
    "    pix = tile_filt - tile_filt.mean(axis=0)\n",
    "    pix /= (pix.std(axis=0) + 1e-9)\n",
    "\n",
    "    # Correlation with reference\n",
    "    corr = np.mean(ref[:, None] * pix, axis=0)\n",
    "\n",
    "    # Use mean absolute correlation as coherence\n",
    "    return np.mean(np.abs(corr))\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Output tile map\n",
    "# ===============================\n",
    "n_tiles_y = H // TILE_SIZE\n",
    "n_tiles_x = W // TILE_SIZE\n",
    "\n",
    "tile_coherence_map = np.zeros((n_tiles_y, n_tiles_x), dtype=np.float32)\n",
    "\n",
    "# ===============================\n",
    "# Main loop\n",
    "# ===============================\n",
    "with tqdm(total=n_tiles_y * n_tiles_x, desc=\"Computing coherence\") as pbar:\n",
    "    for ty in range(n_tiles_y):\n",
    "        for tx in range(n_tiles_x):\n",
    "\n",
    "            y0 = ty * TILE_SIZE\n",
    "            y1 = y0 + TILE_SIZE\n",
    "            x0 = tx * TILE_SIZE\n",
    "            x1 = x0 + TILE_SIZE\n",
    "\n",
    "            # Extract tile: (T, 16, 16)\n",
    "            tile = video[:, y0:y1, x0:x1]\n",
    "            tile = tile.reshape(T, -1)\n",
    "\n",
    "            # High-pass filter all pixels independently\n",
    "            tile_filt = bandpass_filter(\n",
    "                tile, FRAME_RATE, *BANDPASS\n",
    "            )\n",
    "\n",
    "            # Compute coherence\n",
    "            tile_coherence_map[ty, tx] = coherence_metric(tile_filt)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "# ===============================\n",
    "# Expand to image resolution\n",
    "# ===============================\n",
    "coherence_image = np.repeat(\n",
    "    np.repeat(tile_coherence_map, TILE_SIZE, axis=0),\n",
    "    TILE_SIZE, axis=1\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Visualization\n",
    "# ===============================\n",
    "vmax = np.percentile(coherence_image, DISPLAY_CLIP)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(coherence_image, cmap=\"viridis\", vmin=0, vmax=vmax)\n",
    "plt.title(\"Grid-based subthreshold coherence (\"+str(TILE_SIZE)+\"×\"+str(TILE_SIZE)+\" tiles)\")\n",
    "plt.colorbar(label=\"Mean |pixel–tile correlation|\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# # ===============================\n",
    "# # Visualization (normalized)\n",
    "# # ===============================\n",
    "\n",
    "# # Normalize coherence image to [0, 1] for visualization\n",
    "# coh_norm = coherence_image.astype(np.float32)\n",
    "# coh_norm -= coh_norm.min()\n",
    "# coh_norm /= (coh_norm.max() + 1e-9)  # avoid division by zero\n",
    "\n",
    "# # Optionally clip at DISPLAY_CLIP percentile for display contrast\n",
    "# vmax = np.percentile(coh_norm, DISPLAY_CLIP / 100 * 1.0)\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.imshow(coh_norm, cmap=\"viridis\", vmin=0, vmax=vmax)\n",
    "# plt.title(f\"Grid-based subthreshold coherence ({TILE_SIZE}×{TILE_SIZE} tiles)\")\n",
    "# plt.colorbar(label=\"Mean |pixel–tile correlation|\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7bd0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Visualization (normalized)\n",
    "# ===============================\n",
    "\n",
    "# Normalize coherence image to [0, 1] for visualization\n",
    "coh_norm = coherence_image.astype(np.float32)\n",
    "coh_norm -= coh_norm.min()\n",
    "coh_norm /= (coh_norm.max() + 1e-9)  # avoid division by zero\n",
    "\n",
    "# Optionally clip at DISPLAY_CLIP percentile for display contrast\n",
    "vmax = np.percentile(coh_norm, DISPLAY_CLIP / 100 * 1.0)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(coh_norm, cmap=\"viridis\", vmin=0, vmax=vmax)\n",
    "plt.title(f\"Grid-based subthreshold coherence ({TILE_SIZE}×{TILE_SIZE} tiles)\")\n",
    "plt.colorbar(label=\"Mean |pixel–tile correlation|\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e50ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing coherence: 100%|██████████| 64/64 [01:51<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================\n",
    "# Parameters\n",
    "# ===============================\n",
    "TILE_SIZE = 8\n",
    "H, W = 512, 512\n",
    "FRAME_RATE = FRAME_RATE\n",
    "BANDPASS = BANDPASS\n",
    "DISPLAY_CLIP = 99\n",
    "\n",
    "# ===============================\n",
    "# Coherence metric (vectorized)\n",
    "# ===============================\n",
    "def coherence_metric_batch(tile_filt):\n",
    "    \"\"\"\n",
    "    tile_filt: (T, Npix)\n",
    "    \"\"\"\n",
    "    ref = tile_filt.mean(axis=1)\n",
    "    ref -= ref.mean()\n",
    "    ref /= (ref.std() + 1e-9)\n",
    "\n",
    "    pix = tile_filt - tile_filt.mean(axis=0)\n",
    "    pix /= (pix.std(axis=0) + 1e-9)\n",
    "\n",
    "    corr = np.mean(ref[:, None] * pix, axis=0)\n",
    "    return np.mean(np.abs(corr))\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Output tile map\n",
    "# ===============================\n",
    "n_tiles_y = H // TILE_SIZE\n",
    "n_tiles_x = W // TILE_SIZE\n",
    "\n",
    "tile_coherence_map = np.zeros((n_tiles_y, n_tiles_x), dtype=np.float32)\n",
    "\n",
    "# ===============================\n",
    "# Main loop (fast)\n",
    "# ===============================\n",
    "for ty in tqdm(range(n_tiles_y), desc=\"Computing coherence\"):\n",
    "    y0 = ty * TILE_SIZE\n",
    "    y1 = y0 + TILE_SIZE\n",
    "\n",
    "    # Pull full row of tiles at once → contiguous memory\n",
    "    row = video[:, y0:y1, :].reshape(video.shape[0], TILE_SIZE, n_tiles_x, TILE_SIZE)\n",
    "    row = row.transpose(0, 1, 3, 2).reshape(video.shape[0], -1, n_tiles_x)\n",
    "\n",
    "    for tx in range(n_tiles_x):\n",
    "        tile = row[:, :, tx]\n",
    "\n",
    "        tile_filt = bandpass_filter(tile, FRAME_RATE, *BANDPASS)\n",
    "        #tile_filt = tile.copy()\n",
    "        tile_coherence_map[ty, tx] = coherence_metric_batch(tile_filt)\n",
    "\n",
    "# ===============================\n",
    "# Expand to image resolution\n",
    "# ===============================\n",
    "coherence_image = np.repeat(\n",
    "    np.repeat(tile_coherence_map, TILE_SIZE, axis=0),\n",
    "    TILE_SIZE, axis=1\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Visualization\n",
    "# ===============================\n",
    "vmax = np.percentile(coherence_image, DISPLAY_CLIP)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(coherence_image, cmap=\"viridis\", vmin=0, vmax=vmax)\n",
    "plt.title(\"Grid-based subthreshold coherence (8×8 tiles)\")\n",
    "plt.colorbar(label=\"Mean |pixel–tile correlation|\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e53707bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing coherence: 100%|██████████| 64/64 [00:46<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp        # GPU version of numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================\n",
    "# Parameters\n",
    "# ===============================\n",
    "TILE_SIZE = 8\n",
    "H, W = 512, 512\n",
    "FRAME_RATE = FRAME_RATE\n",
    "BANDPASS = BANDPASS\n",
    "DISPLAY_CLIP = 99\n",
    "\n",
    "# ===============================\n",
    "# Coherence metric (GPU)\n",
    "# ===============================\n",
    "def coherence_metric_batch_gpu(tile_filt):\n",
    "    \"\"\"\n",
    "    tile_filt: cp.array of shape (T, Npix)\n",
    "    \"\"\"\n",
    "    ref = cp.mean(tile_filt, axis=1)\n",
    "    ref -= cp.mean(ref)\n",
    "    ref /= (cp.std(ref) + 1e-9)\n",
    "\n",
    "    pix = tile_filt - cp.mean(tile_filt, axis=0)\n",
    "    pix /= (cp.std(pix, axis=0) + 1e-9)\n",
    "\n",
    "    corr = cp.mean(ref[:, None] * pix, axis=0)\n",
    "    return float(cp.mean(cp.abs(corr)))  # convert back to host float\n",
    "\n",
    "# ===============================\n",
    "# Output tile map\n",
    "# ===============================\n",
    "n_tiles_y = H // TILE_SIZE\n",
    "n_tiles_x = W // TILE_SIZE\n",
    "tile_coherence_map = np.zeros((n_tiles_y, n_tiles_x), dtype=np.float32)\n",
    "\n",
    "# ===============================\n",
    "# Main loop (row-wise, GPU compute)\n",
    "# ===============================\n",
    "for ty in tqdm(range(n_tiles_y), desc=\"Computing coherence\"):\n",
    "    y0 = ty * TILE_SIZE\n",
    "    y1 = y0 + TILE_SIZE\n",
    "\n",
    "    # Pull full row of tiles → contiguous memory\n",
    "    row = video[:, y0:y1, :].reshape(video.shape[0], TILE_SIZE, n_tiles_x, TILE_SIZE)\n",
    "    row = row.transpose(0, 1, 3, 2).reshape(video.shape[0], -1, n_tiles_x)\n",
    "\n",
    "    for tx in range(n_tiles_x):\n",
    "        tile = row[:, :, tx]\n",
    "\n",
    "        # Copy tile to GPU\n",
    "        tile_gpu = cp.asarray(tile)\n",
    "\n",
    "        # Compute coherence on GPU\n",
    "        tile_coherence_map[ty, tx] = coherence_metric_batch_gpu(tile_gpu)\n",
    "\n",
    "        # Free GPU memory immediately\n",
    "        del tile_gpu\n",
    "        cp._default_memory_pool.free_all_blocks()\n",
    "\n",
    "# ===============================\n",
    "# Expand to image resolution\n",
    "# ===============================\n",
    "coherence_image = np.repeat(\n",
    "    np.repeat(tile_coherence_map, TILE_SIZE, axis=0),\n",
    "    TILE_SIZE, axis=1\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Visualization\n",
    "# ===============================\n",
    "vmax = np.percentile(coherence_image, DISPLAY_CLIP)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(coherence_image, cmap=\"viridis\", vmin=0, vmax=vmax)\n",
    "plt.title(\"Grid-based subthreshold coherence (8×8 tiles, GPU)\")\n",
    "plt.colorbar(label=\"Mean |pixel–tile correlation|\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb11eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing coherence map with 28 parallel jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1024 [00:00<?, ?it/s][Parallel(n_jobs=28)]: Using backend LokyBackend with 28 concurrent workers.\n",
      "  5%|▌         | 56/1024 [00:03<01:01, 15.62it/s] [Parallel(n_jobs=28)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=28)]: Done  16 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=28)]: Done  29 tasks      | elapsed:    4.5s\n",
      "  8%|▊         | 84/1024 [00:04<00:55, 17.03it/s][Parallel(n_jobs=28)]: Done  42 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=28)]: Done  57 tasks      | elapsed:    5.9s\n",
      " 11%|█         | 112/1024 [00:05<00:50, 17.96it/s][Parallel(n_jobs=28)]: Done  72 tasks      | elapsed:    6.5s\n",
      " 14%|█▎        | 140/1024 [00:07<00:45, 19.52it/s][Parallel(n_jobs=28)]: Done  89 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=28)]: Done 106 tasks      | elapsed:    7.9s\n",
      " 16%|█▋        | 168/1024 [00:08<00:38, 22.02it/s][Parallel(n_jobs=28)]: Done 125 tasks      | elapsed:    8.5s\n",
      " 19%|█▉        | 196/1024 [00:09<00:37, 22.14it/s][Parallel(n_jobs=28)]: Done 144 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=28)]: Done 165 tasks      | elapsed:   10.2s\n",
      " 22%|██▏       | 224/1024 [00:10<00:35, 22.57it/s][Parallel(n_jobs=28)]: Done 186 tasks      | elapsed:   11.0s\n",
      " 25%|██▍       | 252/1024 [00:11<00:32, 24.10it/s][Parallel(n_jobs=28)]: Done 209 tasks      | elapsed:   12.0s\n",
      " 27%|██▋       | 280/1024 [00:12<00:30, 24.24it/s][Parallel(n_jobs=28)]: Done 232 tasks      | elapsed:   12.9s\n",
      " 30%|███       | 308/1024 [00:13<00:28, 24.91it/s][Parallel(n_jobs=28)]: Done 257 tasks      | elapsed:   14.0s\n",
      " 33%|███▎      | 336/1024 [00:14<00:27, 25.38it/s][Parallel(n_jobs=28)]: Done 282 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=28)]: Done 309 tasks      | elapsed:   16.1s\n",
      " 36%|███▌      | 364/1024 [00:16<00:28, 23.37it/s][Parallel(n_jobs=28)]: Done 336 tasks      | elapsed:   17.5s\n",
      " 38%|███▊      | 392/1024 [00:17<00:28, 22.31it/s][Parallel(n_jobs=28)]: Done 365 tasks      | elapsed:   18.5s\n",
      " 44%|████▍     | 448/1024 [00:19<00:24, 23.51it/s][Parallel(n_jobs=28)]: Done 394 tasks      | elapsed:   19.8s\n",
      " 46%|████▋     | 476/1024 [00:21<00:24, 22.51it/s][Parallel(n_jobs=28)]: Done 425 tasks      | elapsed:   21.3s\n",
      " 49%|████▉     | 504/1024 [00:22<00:22, 23.59it/s][Parallel(n_jobs=28)]: Done 456 tasks      | elapsed:   22.5s\n",
      " 52%|█████▏    | 532/1024 [00:23<00:20, 24.33it/s][Parallel(n_jobs=28)]: Done 489 tasks      | elapsed:   23.8s\n",
      " 55%|█████▍    | 560/1024 [00:24<00:19, 23.42it/s][Parallel(n_jobs=28)]: Done 522 tasks      | elapsed:   25.4s\n",
      " 57%|█████▋    | 588/1024 [00:25<00:18, 23.89it/s][Parallel(n_jobs=28)]: Done 557 tasks      | elapsed:   27.3s\n",
      " 63%|██████▎   | 644/1024 [00:28<00:17, 22.00it/s][Parallel(n_jobs=28)]: Done 592 tasks      | elapsed:   28.7s\n",
      " 66%|██████▌   | 672/1024 [00:29<00:15, 22.09it/s][Parallel(n_jobs=28)]: Done 629 tasks      | elapsed:   30.3s\n",
      " 68%|██████▊   | 700/1024 [00:31<00:16, 19.95it/s][Parallel(n_jobs=28)]: Done 666 tasks      | elapsed:   32.1s\n",
      " 74%|███████▍  | 756/1024 [00:33<00:11, 22.36it/s][Parallel(n_jobs=28)]: Done 705 tasks      | elapsed:   34.0s\n",
      " 77%|███████▋  | 784/1024 [00:35<00:11, 21.01it/s][Parallel(n_jobs=28)]: Done 744 tasks      | elapsed:   35.5s\n",
      " 79%|███████▉  | 812/1024 [00:36<00:09, 21.51it/s][Parallel(n_jobs=28)]: Done 785 tasks      | elapsed:   37.5s\n",
      " 85%|████████▍ | 868/1024 [00:38<00:07, 22.15it/s][Parallel(n_jobs=28)]: Done 826 tasks      | elapsed:   39.2s\n",
      " 88%|████████▊ | 896/1024 [00:39<00:05, 23.98it/s][Parallel(n_jobs=28)]: Done 869 tasks      | elapsed:   41.0s\n",
      " 93%|█████████▎| 952/1024 [00:42<00:03, 22.14it/s][Parallel(n_jobs=28)]: Done 912 tasks      | elapsed:   42.8s\n",
      "100%|██████████| 1024/1024 [00:44<00:00, 22.94it/s]\n",
      "[Parallel(n_jobs=28)]: Done 957 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=28)]: Done 1024 out of 1024 | elapsed:   47.5s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# 5. Correlation computation\n",
    "# ===============================\n",
    "correlation_map = np.zeros((H, W), dtype=np.float32)\n",
    "count_map = np.zeros((H, W), dtype=np.int32)\n",
    "\n",
    "for y in range(HALF, H - HALF):\n",
    "    for x in range(HALF, W - HALF):\n",
    "\n",
    "        # Extract 3x3 pixel signals\n",
    "        patch = video[:, y-HALF:y+HALF+1, x-HALF:x+HALF+1]\n",
    "        patch = patch.reshape(T, -1)\n",
    "\n",
    "        # Band-pass filter each pixel independently\n",
    "        patch_filt = bandpass_filter(\n",
    "            patch, FRAME_RATE, *BANDPASS\n",
    "        )\n",
    "\n",
    "        # Correlation matrix (9x9)\n",
    "        C = np.corrcoef(patch_filt.T)\n",
    "\n",
    "        # Mean off-diagonal correlation\n",
    "        mean_corr = (\n",
    "            np.sum(C) - np.trace(C)\n",
    "        ) / (C.size - C.shape[0])\n",
    "\n",
    "        # Assign correlation to all 9 pixels\n",
    "        correlation_map[y-HALF:y+HALF+1,\n",
    "                        x-HALF:x+HALF+1] += mean_corr\n",
    "        count_map[y-HALF:y+HALF+1,\n",
    "                  x-HALF:x+HALF+1] += 1\n",
    "\n",
    "# Normalize overlapping contributions\n",
    "correlation_map /= np.maximum(count_map, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271dc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================\n",
    "# 5. Correlation computation (with progress bar)\n",
    "# ===============================\n",
    "correlation_map = np.zeros((H, W), dtype=np.float32)\n",
    "count_map = np.zeros((H, W), dtype=np.int32)\n",
    "\n",
    "total_pixels = (H - 2*HALF) * (W - 2*HALF)\n",
    "\n",
    "with tqdm(total=total_pixels, desc=\"Computing 3×3 correlations\") as pbar:\n",
    "    for y in range(HALF, H - HALF):\n",
    "        for x in range(HALF, W - HALF):\n",
    "\n",
    "            # Extract 3x3 pixel signals\n",
    "            patch = video[:, y-HALF:y+HALF+1, x-HALF:x+HALF+1]\n",
    "            patch = patch.reshape(T, -1)\n",
    "\n",
    "            # Band-pass filter each pixel independently\n",
    "            patch_filt = bandpass_filter(\n",
    "                patch, FRAME_RATE, *BANDPASS\n",
    "            )\n",
    "\n",
    "            # Correlation matrix (9x9)\n",
    "            C = np.corrcoef(patch_filt.T)\n",
    "\n",
    "            # Mean off-diagonal correlation\n",
    "            mean_corr = (\n",
    "                np.sum(C) - np.trace(C)\n",
    "            ) / (C.size - C.shape[0])\n",
    "\n",
    "            # Accumulate correlation to pixels\n",
    "            correlation_map[y-HALF:y+HALF+1,\n",
    "                            x-HALF:x+HALF+1] += mean_corr\n",
    "            count_map[y-HALF:y+HALF+1,\n",
    "                      x-HALF:x+HALF+1] += 1\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "# Normalize overlapping contributions\n",
    "correlation_map /= np.maximum(count_map, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# 6. Debug: correlation matrix of one patch\n",
    "# ===============================\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(C, cmap=\"viridis\", vmin=-1, vmax=1)\n",
    "plt.colorbar(label=\"Correlation\")\n",
    "plt.title(\"3×3 patch correlation matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===============================\n",
    "# 7. Final correlation image\n",
    "# ===============================\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(correlation_map, cmap=\"inferno\")\n",
    "plt.colorbar(label=\"Mean pairwise correlation\")\n",
    "plt.title(\"Local 3×3 pixel correlation map\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1736187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_images = np.stack([img, img, coherence_image], axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing local correlations movie with RAM FILE...\n",
      "Done.\n",
      "C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV3_T3new\\FOV3_T3_corr.tif\n",
      "(512, 512, 3)\n",
      "Saved: C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV3_T3new\\FOV3_T3_py.png\n",
      "Running Mask R-CNN inference...\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        200\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               200\n",
      "MEAN_PIXEL                     [91.11 91.11 86.76]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           neuron\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.3\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 1, 1)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
      "STEPS_PER_EPOCH                163\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           100\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               1\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     1644364 [deprecation.py:            new_func():554][24200] From c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (512, 512, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 512, 512, 3)      min:  -91.11000  max:  168.24000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  int32\n",
      "anchors                  shape: (1, 65472, 4)         min:   -0.04428  max:    1.01297  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MADE FIGURE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Computing local correlations movie with RAM FILE...\")\n",
    "cn = local_correlations_movie_offline(mc.mmap_file[0], fr=fr, window=fr*4, stride=fr*4, winSize_baseline=fr*2, remove_baseline=True,\n",
    "                                    gaussian_blur = gaussian_blur, dview=dview).max(axis=0)\n",
    "#55 s with local_correlations_movie_offline\n",
    "print(\"Done.\")\n",
    "##\n",
    "\n",
    "img_corr = (cn - np.mean(cn))/np.std(cn)\n",
    "summary_images = np.stack([img, img, img_corr], axis=0).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50a9cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2_corr.tif\n",
      "(512, 512, 3)\n",
      "Saved: C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2_py.png\n",
      "Running Mask R-CNN inference...\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        200\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               200\n",
      "MEAN_PIXEL                     [91.11 91.11 86.76]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           neuron\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.3\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 1, 1)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
      "STEPS_PER_EPOCH                163\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           100\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               1\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     4751613 [deprecation.py:            new_func():554][31880] From c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (512, 512, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 512, 512, 3)      min:  -91.11000  max:  168.24000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  int32\n",
      "anchors                  shape: (1, 65472, 4)         min:   -0.04428  max:    1.01297  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MADE FIGURE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cm.movie(summary_images).save(fname[:-5]+'_summary_images.tif')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(summary_images[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(fname[:-4]+'_mean.tif', format='tif', bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(summary_images[2], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(fname[:-4]+'_corr.tif', format='tif', bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "\n",
    "img = summary_images.transpose([1, 2, 0])\n",
    "\n",
    "\n",
    "print(fname[:-4]+'_corr.tif')\n",
    "height, width = img.shape[:2]\n",
    "print(img.shape)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Extract channels like MATLAB\n",
    "# --------------------------------------------------------------\n",
    "R = img[:, :, 0]\n",
    "B = img[:, :, 2]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# MATLAB-style normalization (mat2gray + uint8)\n",
    "# --------------------------------------------------------------\n",
    "def normalize_like_matlab(x):\n",
    "    x = x.astype(np.float64)\n",
    "    mn = x.min()\n",
    "    mx = x.max()\n",
    "    x = (x - mn) / (mx - mn + 1e-12)\n",
    "\n",
    "    # MATLAB uint8 applies rounding, not floor\n",
    "    x = np.round(255 * x).astype(np.uint8)\n",
    "    return x\n",
    "\n",
    "R_norm = normalize_like_matlab(R)\n",
    "B_norm = normalize_like_matlab(B)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Build MATLAB-equivalent RGB (R,R,B)\n",
    "# --------------------------------------------------------------\n",
    "rgb = np.stack([R_norm, R_norm, B_norm], axis=2).astype(np.uint8)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Save as PNG (MATLAB-compatible pixel data)\n",
    "# --------------------------------------------------------------\n",
    "outname = fname[:-4] + \"_py.png\"\n",
    "Image.fromarray(rgb).save(outname)\n",
    "\n",
    "print(\"Saved:\", outname)\n",
    "img = rgb.copy()\n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "print(\"Running Mask R-CNN inference...\")\n",
    "weights_path=\"C:/Users/ICNLab/caiman_data/testdata/testdata/mask_rcnn_neuron_0012.h5\"\n",
    "#download_model('mask_rcnn')\n",
    "#ROIs, r = utils.mrcnn_inference(img, size_range=[0, 40], weights_path=weights_path, display_result=True)\n",
    "r = utils.mrcnn_inference(img, size_range=[0, 40], weights_path=weights_path, display_result=True)\n",
    "ROIs = r['masks'].transpose([2, 0, 1])\n",
    "cm.movie(ROIs).save(fname[:-4]+'newmrcnn_ROIs.hdf5')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(summary_images[1])\n",
    "axs[1].imshow(ROIs.sum(0))\n",
    "axs[0].set_title('mean image')\n",
    "axs[1].set_title('masks')\n",
    "plt.savefig(fname[:-6] + 'newmrcnn_ROIs.png', format='png', bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "764be18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running VOLPY fit...\n",
      "Starting VOLPY spike detection...\n",
      "Done.\n",
      "[  2   3   4   5   6   8   9  10  11  13  14  16  18  19  20  21  24  25\n",
      "  26  28  31  32  35  36  38  39  47  48  50  51  52  53  54  55  57  64\n",
      "  68  70  74  75  76  77  83  84  88  89  91  92  93  98 100 104 105 106]\n",
      "Saved VOLPY estimates to: C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2new_volpy.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "        backend='local', n_processes=None, single_thread=False, maxtasksperchild=1)\n",
    "\n",
    "##\n",
    "# ROIs = ROIs                                   # region of interests\n",
    "# index = list(range(len(ROIs)))                # index of neurons\n",
    "# weights = None                                # if None, use ROIs for initialization; to reuse weights check reuse weights block\n",
    "\n",
    "# template_size = 0.02                          # half size of the window length for spike templates, default is 20 ms\n",
    "# context_size = 35                             # number of pixels surrounding the ROI to censor from the background PCA\n",
    "# visualize_ROI = False                         # whether to visualize the region of interest inside the context region\n",
    "# hp_freq_pb = 1 / 3                            # parameter for high-pass filter to remove photobleaching\n",
    "# clip = 100                                    # maximum number of spikes to form spike template\n",
    "# threshold_method = 'adaptive_threshold'       # adaptive_threshold or simple\n",
    "# min_spikes= 10                                # minimal spikes to be found\n",
    "# pnorm = 0.5                                   # a variable deciding the amount of spikes chosen for adaptive threshold method\n",
    "# threshold = 2                                 # threshold for finding spikes only used in simple threshold method, Increase the threshold to find less spikes\n",
    "# do_plot = False                               # plot detail of spikes, template for the last iteration\n",
    "# ridge_bg= 0.05                                # ridge regression regularizer strength for background removement, larger value specifies stronger regularization\n",
    "# sub_freq = 20                                 # frequency for subthreshold extraction\n",
    "# weight_update = 'ridge'                       # ridge or NMF for weight update\n",
    "# n_iter = 2                                    # number of iterations alternating between estimating spike times and spatial filters\n",
    "\n",
    "#Modified parameters\n",
    "template_size = 0.02                          # half size of the window length for spike templates, default is 20 ms\n",
    "context_size = 35                             # number of pixels surrounding the ROI to censor from the background PCA\n",
    "visualize_ROI = False                         # whether to visualize the region of interest inside the context region\n",
    "hp_freq_pb = 70                          # parameter for high-pass filter to remove photobleaching\n",
    "clip = 100                                    # maximum number of spikes to form spike template\n",
    "threshold_method = 'adaptive_threshold'       # adaptive_threshold or simple\n",
    "min_spikes= 10                                # minimal spikes to be found\n",
    "pnorm = 0.1                             # a variable deciding the amount of spikes chosen for adaptive threshold method\n",
    "threshold = 2                                 # threshold for finding spikes only used in simple threshold method, Increase the threshold to find less spikes\n",
    "do_plot = False                               # plot detail of spikes, template for the last iteration\n",
    "ridge_bg= 0.05                                # ridge regression regularizer strength for background removement, larger value specifies stronger regularization\n",
    "sub_freq = 20                                 # frequency for subthreshold extraction\n",
    "weight_update = 'ridge'                       # ridge or NMF for weight update\n",
    "n_iter = 2                                    # number of iterations alternating between estimating spike times and spatial filters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opts_dict={'fnames': ram_path,   #'fnames': fname_new,\n",
    "        'ROIs': ROIs,\n",
    "        'index': index,\n",
    "        'weights': weights,\n",
    "        'template_size': template_size,\n",
    "        'context_size': context_size,\n",
    "        'visualize_ROI': visualize_ROI,\n",
    "        'hp_freq_pb': hp_freq_pb,\n",
    "        'clip': clip,\n",
    "        'threshold_method': threshold_method,\n",
    "        'min_spikes':min_spikes,\n",
    "        'pnorm': pnorm,\n",
    "        'threshold': threshold,\n",
    "        'do_plot':do_plot,\n",
    "        'ridge_bg':ridge_bg,\n",
    "        'sub_freq': sub_freq,\n",
    "        'weight_update': weight_update,\n",
    "        'n_iter': n_iter}\n",
    "\n",
    "opts.change_params(params_dict=opts_dict);\n",
    "\n",
    "vpy = VOLPY(n_processes=n_processes, dview=dview, params=opts)\n",
    "\n",
    "print(\"Running VOLPY fit...\")\n",
    "vpy.fit(n_processes=n_processes, dview=dview)\n",
    "#takes a while to run\n",
    "print(\"Done.\")\n",
    "\n",
    "# Visualize spatial footprints and traces\n",
    "print(np.where(vpy.estimates['locality'])[0])    # neurons that pass locality test\n",
    "# idx = np.where(vpy.estimates['locality'] > 0)[0]\n",
    "# utils.view_components(vpy.estimates, img_corr, idx)\n",
    "\n",
    "\n",
    "##\n",
    "\n",
    "# Reconstructed movie\n",
    "# flip_signal = True    \n",
    "# mv_all = utils.reconstructed_movie(vpy.estimates.copy(), fnames=mc.mmap_file,\n",
    "#                                         idx=idx, scope=(0,1000), flip_signal=flip_signal)\n",
    "#mv_all.play(fr=40, magnification=3)\n",
    "\n",
    "##\n",
    "vpy.estimates['ROIs'] = ROIs\n",
    "save_name = fname[:-4]+'new_volpy'\n",
    "np.save(save_name, vpy.estimates)\n",
    "\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)\n",
    "\n",
    "print(\"Saved VOLPY estimates to:\", save_name + '.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48e4a0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'estimates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimates\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vpy\u001b[38;5;241m.\u001b[39mestimates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspikes\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(vpy\u001b[38;5;241m.\u001b[39mestimates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnr\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'estimates'"
     ]
    }
   ],
   "source": [
    "print(vpy.estimates.keys())\n",
    "print(len(vpy.estimates['spikes']))\n",
    "print(vpy.estimates['snr']) \n",
    "\n",
    "#print length of each key's data:\n",
    "for key in vpy.estimates.keys():\n",
    "    print(f\"{key}: {len(vpy.estimates[key])}\")\n",
    "\n",
    "#print number of neurons with snr > 3\n",
    "snr_threshold = 3.0\n",
    "high_snr_neurons = np.sum(vpy.estimates['snr'] > snr_threshold)\n",
    "print(f\"Number of neurons with SNR > {snr_threshold}: {high_snr_neurons}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "250eae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved VOLPY figure to: C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2_volpy.pdf\n",
      "Saving VOLPY data to MAT file...\n",
      "Converting data types for fast saving...\n",
      "  Converted 't' to float32 array.\n",
      "  Converted 'ts' to float32 array.\n",
      "  Converted 't_rec' to float32 array.\n",
      "  Converted 't_sub' to float32 array.\n",
      "  Converted 'templates' to float32 array.\n",
      "  Converted 'snr' to float32 array.\n",
      "  Converted 'thresh' to float32 array.\n",
      "  Converted 'weights' to float32 array.\n",
      "  Converted 'locality' to float32 array.\n",
      "  Converted 'context_coord' to float32 array.\n",
      "  Converted 'F0' to float32 array.\n",
      "  Converted 'dFF' to float32 array.\n",
      "  Converted 'raster' to float32 array.\n",
      "  Converted 'firing_rate' to float32 array.\n",
      "  Converted 'num_spikes' to int32 array.\n",
      "Data type conversion complete.\n",
      "Saved VOLPY data to: C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2_2volpy.mat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##\n",
    "vpy = vpy.estimates\n",
    "try:\n",
    "    # %% plotting all traces\n",
    "\n",
    "    num_frames = np.max(vpy['dFF'].shape)\n",
    "    dur = num_frames/640\n",
    "    vpy['cellID'] = []\n",
    "    vpy['raster'] = np.zeros_like(vpy['dFF'])\n",
    "    vpy['firing_rate'] = np.zeros_like(vpy['dFF'])\n",
    "\n",
    "    for i in range(vpy['dFF'].shape[0]-1):\n",
    "        vpy['raster'][i,vpy['spikes'][i]] = 1\n",
    "        vpy['firing_rate'][i] = savgol_filter(np.convolve(vpy['raster'][i]*640,np.ones(32)/32,mode='same'),64,1)\n",
    "\n",
    "        if np.sqrt(np.var(vpy['templates'][i], ddof=1))>0.5:\n",
    "            vpy['cellID'].append(i)\n",
    "\n",
    "    if len(vpy['cellID'])>0:\n",
    "        dFF = np.array(vpy['dFF']).astype(float)\n",
    "        R = np.corrcoef(dFF)\n",
    "        r = np.array(np.where(np.triu(R,1)>0.7))\n",
    "        for i in range(0,r.shape[1]):\n",
    "            if np.max(dFF[r[0][i]]) < np.max(dFF[r[1][i]]):\n",
    "                r[1][i] = r[0][i]\n",
    "\n",
    "        vpy['cellID'] = [x for x in vpy['cellID'] if x not in r[1]]\n",
    "\n",
    "    cells = np.array(vpy['cellID'])\n",
    "    time = np.arange(0,dur,1/640)\n",
    "\n",
    "    fig = plt.figure(figsize=(8.0, 11.0), facecolor='w',constrained_layout=True)\n",
    "    spec = fig.add_gridspec(ncols=3, nrows=5, width_ratios=[1,1,1], height_ratios=[2, 5,1,1,1])\n",
    "    ax1 = fig.add_subplot(spec[0, 0])\n",
    "    ax2 = fig.add_subplot(spec[0, 1])\n",
    "    ax_text = fig.add_subplot(spec[0, 2],facecolor='w')\n",
    "    ax3 = fig.add_subplot(spec[1, :],facecolor='w')\n",
    "    ax4 = fig.add_subplot(spec[4, :],facecolor='w')\n",
    "    ax5 = fig.add_subplot(spec[2, :],facecolor='w')\n",
    "    ax5r = ax5.twinx()\n",
    "    ax6 = fig.add_subplot(spec[3, :],facecolor='w')\n",
    "    #ax7 = fig.add_subplot(spec[4, :],facecolor='w')\n",
    "\n",
    "    ax1.imshow(img[:,:,1], cmap='gray')\n",
    "    ax2.imshow(img[:,:,2], cmap='gray')\n",
    "    ax1.set_title('Mean image',color='k',fontsize=14)\n",
    "    ax2.set_title('Corr image',color='k',fontsize=14)\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "    ax_text.set_axis_off()\n",
    "\n",
    "    llim = 0\n",
    "    if len(cells)>0:\n",
    "        pos_cells = []\n",
    "        neg_cells = []\n",
    "        b, a = butter(1, [1.5, 100], fs=640, btype='band')\n",
    "        k = 1\n",
    "        for i in range(0, len(cells)):\n",
    "            if ''.join(vpy['polarity'][cells[i]]) in 'negative':\n",
    "                color = '#9AAB3A'\n",
    "                mult = -1\n",
    "                neg_cells.append(cells[i])\n",
    "            else:\n",
    "                color = '#54A0A8'\n",
    "                mult = 1\n",
    "                pos_cells.append(cells[i])\n",
    "            y = np.array(lfilter(b,a,stats.zscore(np.array(vpy['dFF'][cells[i]] * mult * 100,dtype=np.float32))) + ((k - 1) * 8)).reshape(1,num_frames)\n",
    "            ax3.plot(llim+time,y[0,:],color, linewidth=0.3)\n",
    "            ax3.plot(llim+time[vpy['spikes'][cells[i]]],np.max(y)*np.ones(vpy['spikes'][cells[i]].shape[0]),\"|\",color='firebrick',markersize=2)\n",
    "            k = k + 1\n",
    "\n",
    "\n",
    "        if len(pos_cells)>0:\n",
    "            mean_fr_pos = np.mean(vpy['firing_rate'][pos_cells,:], axis=0)\n",
    "            sem_pos = stats.sem(np.array(vpy['firing_rate'][pos_cells,:],dtype=np.float32), axis=0)\n",
    "            ax5r.plot(llim+time, np.array(mean_fr_pos,dtype='float32').ravel(), label='Mean firing rate', color='#54A0A8',linewidth=0.3)\n",
    "            ax5r.fill_between(llim+time, np.array(mean_fr_pos - sem_pos,dtype='float32').ravel(), np.array(mean_fr_pos + sem_pos,dtype='float32'), color='#54A0A8', alpha=0.3, label='SEM')\n",
    "            ax5.set_ylabel('Firing rate (Hz)',color='#54A0A8',fontsize=12)\n",
    "            ax5r.tick_params(axis ='y', labelcolor = '#54A0A8')\n",
    "        if len(neg_cells)>0:\n",
    "            mean_fr_neg = np.mean(vpy['firing_rate'][neg_cells,:], axis=0)\n",
    "            sem_neg = stats.sem(np.array(vpy['firing_rate'][neg_cells,:],dtype=np.float32), axis=0)\n",
    "            ax5.plot(llim+time, np.array(mean_fr_neg,dtype='float32').ravel(), label='Mean firing rate', color='#9AAB3A',linewidth=0.3)\n",
    "            ax5.fill_between(llim+time, np.array(mean_fr_neg - sem_neg,dtype='float32').ravel(), np.array(mean_fr_neg + sem_neg,dtype='float32'), color='#9AAB3A', alpha=0.3, label='SEM')\n",
    "            ax5.set_ylabel('Firing rate (Hz)',color='#9AAB3A',fontsize=12)\n",
    "            ax5r.tick_params(axis ='y', labelcolor = '#9AAB3A')\n",
    "\n",
    "    wheel_mat = os.path.dirname(fname) + '\\\\Wheel.mat'\n",
    "    if os.path.exists(wheel_mat):\n",
    "        wheel=mat73.loadmat(wheel_mat)\n",
    "        if 'behavior' in wheel:\n",
    "            ax4.plot(wheel['behavior'][:,0],wheel['behavior'][:,1],'r',linewidth=1.2)\n",
    "            if wheel['behavior'].shape[1]>2:\n",
    "                ax4.plot(wheel['behavior'][:,0],wheel['behavior'][:,2],'k',linewidth=1)\n",
    "            ax4.set_ylabel('Behavior',color='k',fontsize=12)\n",
    "            ax4.set_yticks([-1,0,1])\n",
    "            ax4.set_ylim([-2,2])\n",
    "\n",
    "        if wheel['data_time'].any():\n",
    "            whl_time = np.arange(0,np.max(wheel['data_time']),1/640)\n",
    "            wheel_interp = np.interp(whl_time, wheel['data_time'], wheel['data_pos'])\n",
    "            speed = np.zeros_like(wheel_interp)\n",
    "            for i in range(0,len(whl_time)-1):\n",
    "                speed[i] = (wheel_interp[i+1]-wheel_interp[i])/(whl_time[i+1]-whl_time[i])\n",
    "\n",
    "            #speed[speed>100] = 0\n",
    "            #speed[speed<0] = 0\n",
    "            speed = savgol_filter(speed,64,1)\n",
    "            ax6.plot(whl_time,speed,'k',linewidth=1)\n",
    "            ax6.set_ylabel('Speed (cm/s)',color='k',fontsize=12)\n",
    "            #ax7.plot(whl_time,speed,'w',linewidth=1)\n",
    "            #ax7.set_ylabel('Speed (cm/s)',color='k',fontsize=12)\n",
    "\n",
    "        ax_text.text(0.5, 0.8, 'Mouse = ' + wheel['mouse'], color='k',fontsize=10, ha='center')\n",
    "        ax_text.text(0.5, 0.4, 'Stimulus = ' + wheel['stimulus'], color='k',fontsize=10, ha='center')\n",
    "        ax_text.text(0.5, 0.6, 'Date = ' + str(np.array(wheel['currentdate'],dtype='int32')), color='k',fontsize=10, ha='center')\n",
    "        #ax_text.text(0.5, 0.2, 'File = ' + wheel['file'], color='w',fontsize=10, ha='center')\n",
    "        if wheel['stimulus']=='Map' and 'rand_num' in wheel:\n",
    "            ax_text.text(0.5, 0, 'Field = ' + \" \".join(str(x) for x in wheel['rand_num'].astype(int)), color='k',fontsize=10, ha='center')\n",
    "        elif wheel['stimulus']=='Tuning' and 'rand_num' in wheel:\n",
    "            ax_text.text(0.5, 0, 'Orientation = ' + \" \".join(str(x) for x in wheel['rand_num'].astype(int)), color='k',fontsize=10, ha='center')\n",
    "        elif wheel['stimulus']=='Tuning' and 'rand_num' in wheel:\n",
    "            ax_text.text(0.5, 0, 'Orientation = ' + \" \".join(str(x) for x in wheel['rand_num'].astype(int)), color='k',fontsize=10, ha='center')\n",
    "    else:\n",
    "        print(\"Wheel data does not exist\")\n",
    "\n",
    "\n",
    "    for ax in [ax3,ax4,ax5,ax6]:\n",
    "        ax.tick_params(color='black', labelcolor='black')\n",
    "        ax.set_xlabel('Time (sec)',color='k',fontsize=12)\n",
    "        ax.set_xlim([llim,llim+dur])\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('black')\n",
    "    ax3.set_title('dFF',color='k',fontsize=14)\n",
    "    ax3.set_ylabel(r'$\\Delta$F/F (%)',color='k',fontsize=12)\n",
    "\n",
    "\n",
    "    fig.savefig(fname[:-4] + '_volpy.pdf')\n",
    "    #plt.close('all')\n",
    "    \n",
    "    print(\"Saved VOLPY figure to:\", fname[:-4] + '_volpy.pdf')\n",
    "\n",
    "    print(\"Saving VOLPY data to MAT file...\")\n",
    "    vpy['ROIs'] = ROIs\n",
    "    #vpy['rect'] = r['rois']\n",
    "    vpy['img'] = img\n",
    "    del vpy['rawROI']\n",
    "    #scipy.io.savemat(fname[:-4] + '_volpy.mat', {'vpy': vpy}, format='5', do_compression=True)\n",
    "    \n",
    "\n",
    "    print(\"Converting data types for fast saving...\")\n",
    "\n",
    "    # Keys identified from inspection output that need fixing\n",
    "    keys_to_convert_float = [\n",
    "        't', 'ts', 't_rec', 't_sub', 'templates', 'snr', \n",
    "        'thresh', 'weights', 'locality', 'context_coord', 'F0', 'dFF', \n",
    "        'raster', 'firing_rate'\n",
    "    ]\n",
    "\n",
    "    keys_to_convert_int = [\n",
    "        'num_spikes'\n",
    "    ]\n",
    "\n",
    "    # Process float conversions\n",
    "    for key in keys_to_convert_float:\n",
    "        if key in vpy and vpy[key].dtype == object:\n",
    "            try:\n",
    "                # Attempt a direct conversion to float32 (fastest for scientific data)\n",
    "                vpy[key] = np.array(vpy[key], dtype=np.float32)\n",
    "                print(f\"  Converted '{key}' to float32 array.\")\n",
    "            except ValueError:\n",
    "                print(f\"  Could not convert '{key}' to standard array dtype. Keeping as object array.\")\n",
    "\n",
    "    # Process integer conversions\n",
    "    for key in keys_to_convert_int:\n",
    "        if key in vpy and vpy[key].dtype == object:\n",
    "            try:\n",
    "                vpy[key] = np.array(vpy[key], dtype=np.int32)\n",
    "                print(f\"  Converted '{key}' to int32 array.\")\n",
    "            except ValueError:\n",
    "                print(f\"  Could not convert '{key}' to int32 array. Keeping as object array.\")\n",
    "\n",
    "    # Handle variables that are inherently irregular lists that MUST be object arrays in Python, \n",
    "    # but we ensure they are clean for saving.\n",
    "\n",
    "    # Handle 'mean_im', 'cell_n', 'polarity' (irregular shapes/strings)\n",
    "    for key in ['mean_im', 'cell_n', 'polarity']:\n",
    "        if key in vpy and vpy[key].dtype == object:\n",
    "            vpy[key] = np.array(vpy[key], dtype=object) # Ensure they are formally object arrays\n",
    "\n",
    "    # Handle spikes and low_spikes. The try/except handles the 'bool is not iterable' error.\n",
    "    if vpy['spikes'].dtype == object:\n",
    "        vpy['spikes'] = np.array([list(x) for x in vpy['spikes']], dtype=object)\n",
    "        \n",
    "    if vpy['low_spikes'].dtype == object:\n",
    "        try:\n",
    "            # This was causing the TypeError because it was actually a boolean array\n",
    "            vpy['low_spikes'] = np.array([list(x) for x in vpy['low_spikes']], dtype=object)\n",
    "        except TypeError:\n",
    "            # If it's a bool array, just make sure it's saved as a clean boolean array\n",
    "            vpy['low_spikes'] = np.array(vpy['low_spikes'], dtype=bool) \n",
    "\n",
    "\n",
    "    print(\"Data type conversion complete.\")\n",
    "    \n",
    "    scipy.io.savemat(fname[:-4] + '_volpy.mat', {'vpy': vpy}, format='5', do_compression=True)\n",
    "    print(\"Saved VOLPY data to:\", fname[:-4] + '_2volpy.mat')\n",
    "\n",
    "    # vpy.estimates['params'] = opts\n",
    "    # save_name = f'volpy_{os.path.split(fnames)[1][:-5]}_{threshold_method}'\n",
    "    # np.save(fnames[:-4] + '_volpy.npy', vpy.estimates)\n",
    "\n",
    "    #del vpy\n",
    "    # %% STOP CLUSTER and clean up log files\n",
    "\n",
    "\n",
    "    log_files = glob.glob('*_LOG_*')\n",
    "    for log_file in log_files:\n",
    "        os.remove(log_file)\n",
    "except ValueError:\n",
    "    traceback.print_exc()\n",
    "    print(\"No volpy data was saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6d984c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_im', 'cell_n', 't', 'ts', 't_rec', 't_sub', 'spikes', 'low_spikes', 'num_spikes', 'templates', 'snr', 'thresh', 'weights', 'locality', 'context_coord', 'F0', 'dFF', 'polarity', 'ROIs', 'cellID', 'raster', 'firing_rate', 'img'])\n",
      "108\n",
      "[ 2.2832398 -3.5445855 11.29796    7.738044   3.205537   9.663431\n",
      "  1.1494905 -2.0245862  3.4733834  3.959727   2.9571002 16.407326\n",
      " -1.3928297 13.05479    7.9565024 -4.344558   3.3550951 -3.8677661\n",
      " 11.033477   3.3255389 11.836677   1.7227821 -2.2650077 -3.58393\n",
      "  1.7308702  2.0075724  8.213702   4.116227   2.2615964 -1.8638135\n",
      " -3.7907813  2.8585284 15.351904  -0.7349891 -2.5207229  1.5922941\n",
      "  4.4084163 -2.1523283  7.1230984  2.0641942 -3.1359792 -1.7648456\n",
      " -3.37024    1.9081684  3.0166798 -3.6531832  6.004449   5.4073153\n",
      "  4.149292   6.848043   3.460325   9.769232   3.7711208  1.6533691\n",
      "  2.4246879  1.8729694  6.7031975  9.742022  -3.7846487 -2.3734438\n",
      " -3.5294197 12.358633   1.8334635 -4.420713   7.8524823  2.544922\n",
      " -7.6872716 -3.9934042 13.638948  -2.1234348 11.541272  14.034415\n",
      " -3.0491297  1.7575248  3.64621    1.5917386  4.4534903  3.082931\n",
      " -2.5263262 -2.3336682 -3.239728  -3.495469   9.1418085 14.331446\n",
      "  3.34419   -3.3845098  0.7119026 -2.7654107  3.878115   3.9874873\n",
      " -3.354973   3.3470442  3.4587064  3.2739468 -1.388796  -3.2822897\n",
      " -5.0385437  6.0804353  5.739242  -3.8108077  1.7609531  0.5555222\n",
      " -1.6373173  4.513034   2.8002841  4.2649813  4.8515263 -2.7626662]\n",
      "mean_im: 108\n",
      "cell_n: 108\n",
      "t: 108\n",
      "ts: 108\n",
      "t_rec: 108\n",
      "t_sub: 108\n",
      "spikes: 108\n",
      "low_spikes: 108\n",
      "num_spikes: 108\n",
      "templates: 108\n",
      "snr: 108\n",
      "thresh: 108\n",
      "weights: 108\n",
      "locality: 108\n",
      "context_coord: 108\n",
      "F0: 108\n",
      "dFF: 108\n",
      "polarity: 108\n",
      "ROIs: 108\n",
      "cellID: 83\n",
      "raster: 108\n",
      "firing_rate: 108\n",
      "img: 512\n",
      "Neuron 0: locality = 0.0, context_coord = [[255. 111.]\n",
      " [300. 158.]]\n",
      "Neuron 1: locality = 0.0, context_coord = [[345.  65.]\n",
      " [394. 112.]]\n",
      "Neuron 2: locality = 1.0, context_coord = [[439. 410.]\n",
      " [486. 458.]]\n",
      "Neuron 3: locality = 1.0, context_coord = [[ 72. 477.]\n",
      " [121. 511.]]\n",
      "Neuron 4: locality = 1.0, context_coord = [[290. 237.]\n",
      " [337. 284.]]\n",
      "Neuron 5: locality = 1.0, context_coord = [[124.  31.]\n",
      " [173.  78.]]\n",
      "Neuron 6: locality = 1.0, context_coord = [[239. 127.]\n",
      " [284. 172.]]\n",
      "Neuron 7: locality = 0.0, context_coord = [[ 31. 156.]\n",
      " [ 78. 201.]]\n",
      "Neuron 8: locality = 1.0, context_coord = [[254. 189.]\n",
      " [300. 233.]]\n",
      "Neuron 9: locality = 1.0, context_coord = [[307. 384.]\n",
      " [353. 429.]]\n",
      "Neuron 10: locality = 1.0, context_coord = [[ 40. 341.]\n",
      " [ 88. 386.]]\n",
      "Neuron 11: locality = 1.0, context_coord = [[ 73. 357.]\n",
      " [120. 403.]]\n",
      "Neuron 12: locality = 0.0, context_coord = [[268.  55.]\n",
      " [324. 103.]]\n",
      "Neuron 13: locality = 1.0, context_coord = [[421. 342.]\n",
      " [470. 388.]]\n",
      "Neuron 14: locality = 1.0, context_coord = [[156. 319.]\n",
      " [212. 369.]]\n",
      "Neuron 15: locality = 0.0, context_coord = [[  2. 331.]\n",
      " [ 50. 375.]]\n",
      "Neuron 16: locality = 1.0, context_coord = [[351. 270.]\n",
      " [396. 316.]]\n",
      "Neuron 17: locality = 0.0, context_coord = [[211. 182.]\n",
      " [258. 229.]]\n",
      "Neuron 18: locality = 1.0, context_coord = [[439. 396.]\n",
      " [485. 442.]]\n",
      "Neuron 19: locality = 1.0, context_coord = [[ 39. 406.]\n",
      " [ 86. 451.]]\n",
      "Neuron 20: locality = 1.0, context_coord = [[ 32. 219.]\n",
      " [ 83. 271.]]\n",
      "Neuron 21: locality = 1.0, context_coord = [[ 69. 386.]\n",
      " [115. 432.]]\n",
      "Neuron 22: locality = 0.0, context_coord = [[327. 269.]\n",
      " [374. 315.]]\n",
      "Neuron 23: locality = 0.0, context_coord = [[236. 237.]\n",
      " [282. 280.]]\n",
      "Neuron 24: locality = 1.0, context_coord = [[188.  21.]\n",
      " [236.  67.]]\n",
      "Neuron 25: locality = 1.0, context_coord = [[306. 264.]\n",
      " [351. 309.]]\n",
      "Neuron 26: locality = 1.0, context_coord = [[ 75. 237.]\n",
      " [126. 289.]]\n",
      "Neuron 27: locality = 0.0, context_coord = [[238. 441.]\n",
      " [282. 489.]]\n",
      "Neuron 28: locality = 1.0, context_coord = [[141. 295.]\n",
      " [186. 341.]]\n",
      "Neuron 29: locality = 0.0, context_coord = [[117. 409.]\n",
      " [164. 453.]]\n",
      "Neuron 30: locality = 0.0, context_coord = [[ 83. 407.]\n",
      " [129. 450.]]\n",
      "Neuron 31: locality = 1.0, context_coord = [[313. 169.]\n",
      " [357. 211.]]\n",
      "Neuron 32: locality = 1.0, context_coord = [[151.  42.]\n",
      " [201.  89.]]\n",
      "Neuron 33: locality = 0.0, context_coord = [[189.  81.]\n",
      " [234. 126.]]\n",
      "Neuron 34: locality = 0.0, context_coord = [[153. 241.]\n",
      " [196. 289.]]\n",
      "Neuron 35: locality = 1.0, context_coord = [[405.  76.]\n",
      " [456. 121.]]\n",
      "Neuron 36: locality = 1.0, context_coord = [[115. 323.]\n",
      " [161. 367.]]\n",
      "Neuron 37: locality = 0.0, context_coord = [[219. 386.]\n",
      " [266. 435.]]\n",
      "Neuron 38: locality = 1.0, context_coord = [[120. 249.]\n",
      " [169. 298.]]\n",
      "Neuron 39: locality = 1.0, context_coord = [[382. 446.]\n",
      " [428. 492.]]\n",
      "Neuron 40: locality = 0.0, context_coord = [[ 96. 161.]\n",
      " [140. 207.]]\n",
      "Neuron 41: locality = 0.0, context_coord = [[138. 474.]\n",
      " [183. 511.]]\n",
      "Neuron 42: locality = 0.0, context_coord = [[175. 110.]\n",
      " [220. 158.]]\n",
      "Neuron 43: locality = 0.0, context_coord = [[105.  89.]\n",
      " [154. 137.]]\n",
      "Neuron 44: locality = 0.0, context_coord = [[178. 201.]\n",
      " [221. 244.]]\n",
      "Neuron 45: locality = 0.0, context_coord = [[344. 227.]\n",
      " [388. 273.]]\n",
      "Neuron 46: locality = 0.0, context_coord = [[140. 265.]\n",
      " [184. 312.]]\n",
      "Neuron 47: locality = 1.0, context_coord = [[ 74. 284.]\n",
      " [123. 331.]]\n",
      "Neuron 48: locality = 1.0, context_coord = [[320. 127.]\n",
      " [366. 173.]]\n",
      "Neuron 49: locality = 0.0, context_coord = [[148. 353.]\n",
      " [191. 398.]]\n",
      "Neuron 50: locality = 1.0, context_coord = [[405.  50.]\n",
      " [454.  99.]]\n",
      "Neuron 51: locality = 1.0, context_coord = [[ 65. 204.]\n",
      " [114. 249.]]\n",
      "Neuron 52: locality = 1.0, context_coord = [[290.   0.]\n",
      " [341.  44.]]\n",
      "Neuron 53: locality = 1.0, context_coord = [[102. 183.]\n",
      " [148. 228.]]\n",
      "Neuron 54: locality = 1.0, context_coord = [[136. 310.]\n",
      " [181. 355.]]\n",
      "Neuron 55: locality = 1.0, context_coord = [[270. 133.]\n",
      " [315. 176.]]\n",
      "Neuron 56: locality = 0.0, context_coord = [[135. 330.]\n",
      " [179. 375.]]\n",
      "Neuron 57: locality = 1.0, context_coord = [[105. 462.]\n",
      " [157. 508.]]\n",
      "Neuron 58: locality = 0.0, context_coord = [[345. 168.]\n",
      " [391. 212.]]\n",
      "Neuron 59: locality = 0.0, context_coord = [[135. 168.]\n",
      " [182. 215.]]\n",
      "Neuron 60: locality = 0.0, context_coord = [[226.  97.]\n",
      " [272. 140.]]\n",
      "Neuron 61: locality = 0.0, context_coord = [[178. 220.]\n",
      " [224. 267.]]\n",
      "Neuron 62: locality = 0.0, context_coord = [[110. 144.]\n",
      " [156. 189.]]\n",
      "Neuron 63: locality = 0.0, context_coord = [[201.   2.]\n",
      " [247.  48.]]\n",
      "Neuron 64: locality = 1.0, context_coord = [[142. 454.]\n",
      " [187. 503.]]\n",
      "Neuron 65: locality = 0.0, context_coord = [[157. 123.]\n",
      " [202. 171.]]\n",
      "Neuron 66: locality = 0.0, context_coord = [[406. 361.]\n",
      " [450. 404.]]\n",
      "Neuron 67: locality = 0.0, context_coord = [[133. 368.]\n",
      " [181. 413.]]\n",
      "Neuron 68: locality = 1.0, context_coord = [[117. 157.]\n",
      " [160. 203.]]\n",
      "Neuron 69: locality = 0.0, context_coord = [[252. 306.]\n",
      " [296. 350.]]\n",
      "Neuron 70: locality = 1.0, context_coord = [[206. 425.]\n",
      " [257. 471.]]\n",
      "Neuron 71: locality = 0.0, context_coord = [[158. 201.]\n",
      " [205. 248.]]\n",
      "Neuron 72: locality = 0.0, context_coord = [[248. 321.]\n",
      " [292. 369.]]\n",
      "Neuron 73: locality = 0.0, context_coord = [[117. 446.]\n",
      " [162. 491.]]\n",
      "Neuron 74: locality = 1.0, context_coord = [[126. 379.]\n",
      " [171. 425.]]\n",
      "Neuron 75: locality = 1.0, context_coord = [[480.   3.]\n",
      " [511.  47.]]\n",
      "Neuron 76: locality = 1.0, context_coord = [[146.  78.]\n",
      " [190. 124.]]\n",
      "Neuron 77: locality = 1.0, context_coord = [[279.  61.]\n",
      " [327. 109.]]\n",
      "Neuron 78: locality = 0.0, context_coord = [[127. 194.]\n",
      " [173. 245.]]\n",
      "Neuron 79: locality = 0.0, context_coord = [[474. 433.]\n",
      " [511. 478.]]\n",
      "Neuron 80: locality = 0.0, context_coord = [[284. 101.]\n",
      " [328. 147.]]\n",
      "Neuron 81: locality = 0.0, context_coord = [[282. 160.]\n",
      " [327. 205.]]\n",
      "Neuron 82: locality = 0.0, context_coord = [[133. 223.]\n",
      " [176. 268.]]\n",
      "Neuron 83: locality = 1.0, context_coord = [[157. 215.]\n",
      " [200. 260.]]\n",
      "Neuron 84: locality = 1.0, context_coord = [[272. 326.]\n",
      " [314. 369.]]\n",
      "Neuron 85: locality = 0.0, context_coord = [[111. 434.]\n",
      " [158. 479.]]\n",
      "Neuron 86: locality = 0.0, context_coord = [[356. 303.]\n",
      " [400. 351.]]\n",
      "Neuron 87: locality = 0.0, context_coord = [[160.  25.]\n",
      " [207.  69.]]\n",
      "Neuron 88: locality = 1.0, context_coord = [[141. 142.]\n",
      " [188. 185.]]\n",
      "Neuron 89: locality = 1.0, context_coord = [[402. 454.]\n",
      " [446. 498.]]\n",
      "Neuron 90: locality = 0.0, context_coord = [[217. 375.]\n",
      " [262. 424.]]\n",
      "Neuron 91: locality = 1.0, context_coord = [[ 32. 306.]\n",
      " [ 76. 350.]]\n",
      "Neuron 92: locality = 1.0, context_coord = [[332. 286.]\n",
      " [377. 329.]]\n",
      "Neuron 93: locality = 1.0, context_coord = [[ 41. 468.]\n",
      " [ 85. 511.]]\n",
      "Neuron 94: locality = 0.0, context_coord = [[ 72. 327.]\n",
      " [117. 371.]]\n",
      "Neuron 95: locality = 0.0, context_coord = [[469. 103.]\n",
      " [511. 146.]]\n",
      "Neuron 96: locality = 0.0, context_coord = [[128.   6.]\n",
      " [170.  51.]]\n",
      "Neuron 97: locality = 0.0, context_coord = [[136. 439.]\n",
      " [178. 485.]]\n",
      "Neuron 98: locality = 1.0, context_coord = [[ 73. 112.]\n",
      " [121. 160.]]\n",
      "Neuron 99: locality = 0.0, context_coord = [[131. 147.]\n",
      " [173. 190.]]\n",
      "Neuron 100: locality = 1.0, context_coord = [[359. 426.]\n",
      " [406. 470.]]\n",
      "Neuron 101: locality = 0.0, context_coord = [[299. 177.]\n",
      " [342. 220.]]\n",
      "Neuron 102: locality = 0.0, context_coord = [[262.  89.]\n",
      " [309. 134.]]\n",
      "Neuron 103: locality = 0.0, context_coord = [[132. 174.]\n",
      " [176. 216.]]\n",
      "Neuron 104: locality = 1.0, context_coord = [[103. 213.]\n",
      " [147. 258.]]\n",
      "Neuron 105: locality = 1.0, context_coord = [[333. 397.]\n",
      " [381. 440.]]\n",
      "Neuron 106: locality = 1.0, context_coord = [[124. 202.]\n",
      " [168. 249.]]\n",
      "Neuron 107: locality = 0.0, context_coord = [[311. 318.]\n",
      " [357. 362.]]\n",
      "Number of neurons with SNR > 5.0: 26\n"
     ]
    }
   ],
   "source": [
    "print(vpy.keys())\n",
    "print(len(vpy['spikes']))\n",
    "print(vpy['snr']) \n",
    "\n",
    "#print length of each key's data:\n",
    "for key in vpy.keys():\n",
    "    print(f\"{key}: {len(vpy[key])}\")\n",
    "#print the coordinates of each neuron\n",
    "for i in range(len(vpy['spikes'])):\n",
    "    print(f\"Neuron {i}: locality = {vpy['locality'][i]}, context_coord = {vpy['context_coord'][i]}\")    \n",
    "\n",
    "#print number of neurons with snr > 3\n",
    "snr_threshold = 5.0\n",
    "high_snr_neurons = np.sum(vpy['snr'] > snr_threshold)\n",
    "print(f\"Number of neurons with SNR > {snr_threshold}: {high_snr_neurons}\")\n",
    "\n",
    "#display img (512x512x3) stored in dictionary vpy\n",
    "# ===============================\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(vpy['img'], cmap='gray')\n",
    "plt.title('VOLPY mean image')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#overlay each context coordinate box on the img (cood is [(x1,y1), (x2,y2)] format)\n",
    "plt.figure(figsize=(6, 6))      \n",
    "plt.imshow(vpy['img'], cmap='gray')\n",
    "for coord in vpy['context_coord']:\n",
    "    (x1, y1), (x2, y2) = coord\n",
    "    rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='red', facecolor='none', linewidth=1)\n",
    "    plt.gca().add_patch(rect)\n",
    "plt.title('VOLPY context regions')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.16s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "timeseries.save() got an unexpected keyword argument 'fr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m out_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreconstructed_movie.avi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# --- save instead of play ---\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mmv_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# frame rate (same as play)\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmagnification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# same magnification as play\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: timeseries.save() got an unexpected keyword argument 'fr'"
     ]
    }
   ],
   "source": [
    "idx = np.where(vpy['locality'] > 0)[0]\n",
    "flip_signal = True\n",
    "\n",
    "mv_all = utils.reconstructed_movie(\n",
    "    vpy.copy(),\n",
    "    fnames=mc.mmap_file,\n",
    "    idx=idx,\n",
    "    scope=(0, 1000),\n",
    "    flip_signal=flip_signal\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54a5aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.dirname(fname)\n",
    "out_path = os.path.join(out_dir, 'reconstructed_movie.mp4')\n",
    "\n",
    "writer = imageio.get_writer(\n",
    "    out_path,\n",
    "    fps=40,\n",
    "    codec='libx264',\n",
    "    pixelformat='yuv420p'\n",
    ")\n",
    "\n",
    "for frame in mv_all:\n",
    "    f = frame.astype(np.float32)\n",
    "    f -= f.min()\n",
    "    f /= f.max() + 1e-8\n",
    "    f = (255 * f).astype(np.uint8)\n",
    "    writer.append_data(f)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GIF to: C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\reconstructed_last5s_slow.gif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\cbook.py\", line 298, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ICNLab\\anaconda3\\envs\\caiman\\lib\\site-packages\\matplotlib\\widgets.py\", line 592, in <lambda>\n",
      "    return self._observers.connect('changed', lambda val: func(val))\n",
      "  File \"C:\\Users\\ICNLab\\CaImAn_GV\\caiman\\source_extraction\\volpy\\utils.py\", line 364, in update\n",
      "    1.05 * np.max(estimates['t'][idx][i]) * np.ones(estimates['spikes'][idx[i]].shape),\n",
      "AttributeError: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:54\n",
      "Component:54\n",
      "Component:54\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "\n",
    "# --- parameters ---\n",
    "orig_fps = 40          # original frame rate\n",
    "seconds = 5\n",
    "slowdown = 2.0         # 2x slower (increase for more slow-mo)\n",
    "\n",
    "gif_fps = orig_fps / slowdown\n",
    "n_frames = int(seconds * orig_fps)\n",
    "\n",
    "# --- output path ---\n",
    "out_dir = os.path.dirname(fname)\n",
    "gif_path = os.path.join(out_dir, 'reconstructed_last5s_slow.gif')\n",
    "\n",
    "# --- select last frames ---\n",
    "frames = mv_all[-n_frames:]\n",
    "\n",
    "with imageio.get_writer(\n",
    "    gif_path,\n",
    "    mode='I',\n",
    "    fps=gif_fps,\n",
    "    loop=0        # 0 = loop forever\n",
    ") as writer:\n",
    "\n",
    "    for frame in frames:\n",
    "        f = frame.astype(np.float32)\n",
    "\n",
    "        # crop to right third for visibility\n",
    "        h, w = f.shape\n",
    "        f = f[:, 2 * w // 3 : w]\n",
    "\n",
    "        # normalize for visibility\n",
    "        f -= f.min()\n",
    "        f /= f.max() + 1e-8\n",
    "        f = (255 * f).astype(np.uint8)\n",
    "\n",
    "        writer.append_data(f)\n",
    "\n",
    "print(f\"Saved GIF to: {gif_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d90de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\reconstructed_movie.avi\n"
     ]
    }
   ],
   "source": [
    "print(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.close('all')\n",
    "    \n",
    "    print(\"Saved VOLPY figure to:\", fname[:-4] + '_volpy.pdf')\n",
    "\n",
    "    print(\"Saving VOLPY data to MAT file...\")\n",
    "    vpy['ROIs'] = ROIs\n",
    "    #vpy['rect'] = r['rois']\n",
    "    vpy['img'] = img\n",
    "    del vpy['rawROI']\n",
    "    #scipy.io.savemat(fname[:-4] + '_volpy.mat', {'vpy': vpy}, format='5', do_compression=True)\n",
    "    \n",
    "\n",
    "    print(\"Converting data types for fast saving...\")\n",
    "\n",
    "    # Keys identified from inspection output that need fixing\n",
    "    keys_to_convert_float = [\n",
    "        't', 'ts', 't_rec', 't_sub', 'templates', 'snr', \n",
    "        'thresh', 'weights', 'locality', 'context_coord', 'F0', 'dFF', \n",
    "        'raster', 'firing_rate'\n",
    "    ]\n",
    "\n",
    "    keys_to_convert_int = [\n",
    "        'num_spikes'\n",
    "    ]\n",
    "\n",
    "    # Process float conversions\n",
    "    for key in keys_to_convert_float:\n",
    "        if key in vpy and vpy[key].dtype == object:\n",
    "            try:\n",
    "                # Attempt a direct conversion to float32 (fastest for scientific data)\n",
    "                vpy[key] = np.array(vpy[key], dtype=np.float32)\n",
    "                print(f\"  Converted '{key}' to float32 array.\")\n",
    "            except ValueError:\n",
    "                print(f\"  Could not convert '{key}' to standard array dtype. Keeping as object array.\")\n",
    "\n",
    "    # Process integer conversions\n",
    "    for key in keys_to_convert_int:\n",
    "        if key in vpy and vpy[key].dtype == object:\n",
    "            try:\n",
    "                vpy[key] = np.array(vpy[key], dtype=np.int32)\n",
    "                print(f\"  Converted '{key}' to int32 array.\")\n",
    "            except ValueError:\n",
    "                print(f\"  Could not convert '{key}' to int32 array. Keeping as object array.\")\n",
    "\n",
    "    # Handle variables that are inherently irregular lists that MUST be object arrays in Python, \n",
    "    # but we ensure they are clean for saving.\n",
    "\n",
    "    # Handle 'mean_im', 'cell_n', 'polarity' (irregular shapes/strings)\n",
    "    for key in ['mean_im', 'cell_n', 'polarity']:\n",
    "        if key in vpy and vpy[key].dtype == object:\n",
    "            vpy[key] = np.array(vpy[key], dtype=object) # Ensure they are formally object arrays\n",
    "\n",
    "    # Handle spikes and low_spikes. The try/except handles the 'bool is not iterable' error.\n",
    "    if vpy['spikes'].dtype == object:\n",
    "        vpy['spikes'] = np.array([list(x) for x in vpy['spikes']], dtype=object)\n",
    "        \n",
    "    if vpy['low_spikes'].dtype == object:\n",
    "        try:\n",
    "            # This was causing the TypeError because it was actually a boolean array\n",
    "            vpy['low_spikes'] = np.array([list(x) for x in vpy['low_spikes']], dtype=object)\n",
    "        except TypeError:\n",
    "            # If it's a bool array, just make sure it's saved as a clean boolean array\n",
    "            vpy['low_spikes'] = np.array(vpy['low_spikes'], dtype=bool) \n",
    "\n",
    "\n",
    "    print(\"Data type conversion complete.\")\n",
    "    \n",
    "    scipy.io.savemat(fname[:-4] + '_volpy.mat', {'vpy': vpy}, format='5', do_compression=True)\n",
    "    print(\"Saved VOLPY data to:\", fname[:-4] + '_volpy.mat')\n",
    "\n",
    "    # vpy.estimates['params'] = opts\n",
    "    # save_name = f'volpy_{os.path.split(fnames)[1][:-5]}_{threshold_method}'\n",
    "    # np.save(fnames[:-4] + '_volpy.npy', vpy.estimates)\n",
    "\n",
    "    del vpy\n",
    "    # %% STOP CLUSTER and clean up log files\n",
    "\n",
    "\n",
    "    log_files = glob.glob('*_LOG_*')\n",
    "    for log_file in log_files:\n",
    "        os.remove(log_file)\n",
    "except ValueError:\n",
    "    traceback.print_exc()\n",
    "    print(\"No volpy data was saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c3cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_data_structure(data_dict, name='Data Structure', indent=''):\n",
    "    \"\"\"\n",
    "    Recursively inspects a dictionary intended for scipy.io.savemat \n",
    "    and prints the types and shapes of contained variables.\n",
    "    \"\"\"\n",
    "    print(f\"{indent}--- Inspecting: {name} ---\")\n",
    "    \n",
    "    # Check top-level type\n",
    "    if not isinstance(data_dict, dict):\n",
    "        print(f\"{indent}WARNING: Top-level object is not a dictionary. Type: {type(data_dict)}\")\n",
    "        return\n",
    "\n",
    "    for key, value in data_dict.items():\n",
    "        # Handle NumPy arrays\n",
    "        if isinstance(value, np.ndarray):\n",
    "            shape_str = f\"Shape: {value.shape}\"\n",
    "            dtype_str = f\"dtype: {value.dtype}\"\n",
    "            print(f\"{indent}|- '{key}': NumPy Array | {shape_str} | {dtype_str}\")\n",
    "        \n",
    "        # Handle basic Python lists/tuples\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            if len(value) > 0 and isinstance(value[0], (np.ndarray, dict, list, tuple)):\n",
    "                # If it's a list of complex objects, print summary of first element and recurse\n",
    "                print(f\"{indent}|- '{key}': List/Tuple ({len(value)} items). Inspecting first item:\")\n",
    "                # Create a temporary dict just to use the recursive function logic\n",
    "                inspect_data_structure({'Item_0': value[0]}, name=f\"List Item 0 (inside '{key}')\", indent=indent + '  ')\n",
    "            else:\n",
    "                # If it's a simple list (e.g., strings, numbers)\n",
    "                val_type = type(value[0]) if len(value) > 0 else 'Empty'\n",
    "                print(f\"{indent}|- '{key}': List/Tuple ({len(value)} items). Contains: {val_type}\")\n",
    "\n",
    "        # Handle nested dictionaries (MATLAB structures)\n",
    "        elif isinstance(value, dict):\n",
    "            print(f\"{indent}|- '{key}': Nested Dictionary. Recursing:\")\n",
    "            inspect_data_structure(value, name=f\"Nested Dict '{key}'\", indent=indent + '  ')\n",
    "            \n",
    "        # Handle other types\n",
    "        else:\n",
    "            print(f\"{indent}|- '{key}': Other Type: {type(value)}\")\n",
    "\n",
    "    print(f\"{indent}--- End of Inspection: {name} ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdab9897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting: Data Structure ---\n",
      "|- 'vpy': Nested Dictionary. Recursing:\n",
      "  --- Inspecting: Nested Dict 'vpy' ---\n",
      "  |- 'mean_im': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 'cell_n': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 't': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 'ts': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 't_rec': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 't_sub': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 'spikes': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 'low_spikes': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 'num_spikes': NumPy Array | Shape: (76, 3) | dtype: object\n",
      "  |- 'templates': NumPy Array | Shape: (76, 25) | dtype: object\n",
      "  |- 'snr': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 'thresh': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 'weights': NumPy Array | Shape: (76, 512, 512) | dtype: object\n",
      "  |- 'locality': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 'context_coord': NumPy Array | Shape: (76, 2, 2) | dtype: object\n",
      "  |- 'F0': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 'dFF': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 'polarity': NumPy Array | Shape: (76,) | dtype: object\n",
      "  |- 'ROIs': NumPy Array | Shape: (76, 512, 512) | dtype: bool\n",
      "  |- 'cellID': List/Tuple (57 items). Contains: <class 'int'>\n",
      "  |- 'raster': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 'firing_rate': NumPy Array | Shape: (76, 12800) | dtype: object\n",
      "  |- 'img': NumPy Array | Shape: (512, 512, 3) | dtype: uint8\n",
      "  --- End of Inspection: Nested Dict 'vpy' ---\n",
      "--- End of Inspection: Data Structure ---\n"
     ]
    }
   ],
   "source": [
    "inspect_data_structure({'vpy': vpy}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6110bdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data types for fast saving...\n",
      "Data type conversion complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Converting data types for fast saving...\")\n",
    "\n",
    "# Keys identified from inspection output that need fixing\n",
    "keys_to_convert_float = [\n",
    "    't', 'ts', 't_rec', 't_sub', 'templates', 'snr', \n",
    "    'thresh', 'weights', 'locality', 'context_coord', 'F0', 'dFF', \n",
    "    'raster', 'firing_rate'\n",
    "]\n",
    "\n",
    "keys_to_convert_int = [\n",
    "    'num_spikes'\n",
    "]\n",
    "\n",
    "# Process float conversions\n",
    "for key in keys_to_convert_float:\n",
    "    if key in vpy and vpy[key].dtype == object:\n",
    "        try:\n",
    "            # Attempt a direct conversion to float32 (fastest for scientific data)\n",
    "            vpy[key] = np.array(vpy[key], dtype=np.float32)\n",
    "            print(f\"  Converted '{key}' to float32 array.\")\n",
    "        except ValueError:\n",
    "            print(f\"  Could not convert '{key}' to standard array dtype. Keeping as object array.\")\n",
    "\n",
    "# Process integer conversions\n",
    "for key in keys_to_convert_int:\n",
    "    if key in vpy and vpy[key].dtype == object:\n",
    "        try:\n",
    "            vpy[key] = np.array(vpy[key], dtype=np.int32)\n",
    "            print(f\"  Converted '{key}' to int32 array.\")\n",
    "        except ValueError:\n",
    "            print(f\"  Could not convert '{key}' to int32 array. Keeping as object array.\")\n",
    "\n",
    "# Handle variables that are inherently irregular lists that MUST be object arrays in Python, \n",
    "# but we ensure they are clean for saving.\n",
    "\n",
    "# Handle 'mean_im', 'cell_n', 'polarity' (irregular shapes/strings)\n",
    "for key in ['mean_im', 'cell_n', 'polarity']:\n",
    "    if key in vpy and vpy[key].dtype == object:\n",
    "         vpy[key] = np.array(vpy[key], dtype=object) # Ensure they are formally object arrays\n",
    "\n",
    "# Handle spikes and low_spikes. The try/except handles the 'bool is not iterable' error.\n",
    "if vpy['spikes'].dtype == object:\n",
    "    vpy['spikes'] = np.array([list(x) for x in vpy['spikes']], dtype=object)\n",
    "    \n",
    "if vpy['low_spikes'].dtype == object:\n",
    "    try:\n",
    "        # This was causing the TypeError because it was actually a boolean array\n",
    "        vpy['low_spikes'] = np.array([list(x) for x in vpy['low_spikes']], dtype=object)\n",
    "    except TypeError:\n",
    "        # If it's a bool array, just make sure it's saved as a clean boolean array\n",
    "        vpy['low_spikes'] = np.array(vpy['low_spikes'], dtype=bool) \n",
    "\n",
    "\n",
    "print(\"Data type conversion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdd3e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved VOLPY data to: C:\\Users\\ICNLab\\caiman_data\\testdata\\testdata\\FOV1_T2RAM2\\FOV1_T2_volpy.mat\n"
     ]
    }
   ],
   "source": [
    "# Insert this line right after the conversion script you just ran:\n",
    "\n",
    "scipy.io.savemat(fname[:-4] + '_volpy.mat', {'vpy': vpy}, format='5', do_compression=False)\n",
    "\n",
    "print(\"Saved VOLPY data to:\", fname[:-4] + '_volpy.mat')\n",
    "\n",
    "# ... the rest of your original script ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
